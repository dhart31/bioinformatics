import pandas as pd
SAMPLES, = glob_wildcards("raw_data/{sample}.read1.fastq.gz")
PLATFORM_UNITS = ['CXX1234-ACTGAC.1', 'CXX1234-TGACAC.1', 'CXX1234-CTGACT.1', 'CXX1234-TGACAC.1', 'CXX1234-GACACT.1', 'CXX1234-ACACTG.1']
df = pd.DataFrame(
    {
    "sample": SAMPLES,
    "platform_unit": PLATFORM_UNITS},
    index=SAMPLES)
df['rg_id'] = df['sample'].str.extract(r'(.*_Rep\d+)')
df['rg_sm'] = df['sample'].str.extract(r'(.{3})_Rep\d+')
df['rg_lb'] = df['sample'].str.extract(r'(.*_Rep\d+_ERCC-Mix\d+)')
print(df.loc[:, ["rg_id", "rg_sm", "rg_lb"]])
#quit()
rule all:
    input:
        expand("results/hisat2_align/{sample}.bam", sample=df["sample"]),
        #expand("results/fastp_trim/{sample}.trimmed.read1.fastq.gz", sample=SAMPLES),
        #expand("results/fastp_trim/{sample}.trimmed.read2.fastq.gz", sample=SAMPLES),
        #"results/strandedness.txt"
        "results/multiqc_report.html",
        #directory("ref/hisat2_index")

rule check_strandedness:
    input:
        gtf = config["gtf"],
        transcripts = config["transcripts"],
        r1 = "raw_data/HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read1.fastq.gz",
        r2 = "raw_data/HBR_Rep1_ERCC-Mix2_Build37-ErccTranscripts-chr22.read2.fastq.gz"
    output:
        "results/strandedness.txt"
    log:
        "logs/strandedness.log"
    conda:
        "how_are_we_stranded_here"
    shell:
        """
        check_strandedness \
        --gtf {input.gtf}\
        --transcripts {input.transcripts}\
        --reads_1 {input.r1}\
        --reads_2 {input.r2}\
        > {output} 2> {log}
        """

rule fastp_trim:
    input:
        r1 = "raw_data/{sample}.read1.fastq.gz",
        r2 = "raw_data/{sample}.read2.fastq.gz"
    output:
        r1 = "results/fastp_trim/{sample}.trimmed.read1.fastq.gz",
        r2 = "results/fastp_trim/{sample}.trimmed.read2.fastq.gz",
        json = "results/fastp_trim/{sample}.json",
        html = "results/fastp_trim/{sample}.html"
    conda:
        "fastp"
    params:
        version = "software_mqc_versions.yaml"
    log:
        "logs/fastp_trim/{sample}.log"
    params:
        version = "software_mqc_versions.yaml"
    shell:
        """
        fastp \
        -i {input.r1} -I {input.r2} \
        -o {output.r1} -O {output.r2} \
        -j {output.json} -h {output.html} \
        2> {log};

        version=$(fastp --version 2>&1 | cut -f 2 -d ' ');
        echo "fastp: "$version > {params.version}
        """

rule hisat2_index:
    input:
        gtf = config["gtf"],
        fasta = config["genome_fasta"]
    output:
        index = directory("ref/hisat2_index")
    conda:
        "hisat2"
    log:
        "logs/hisat2_index.log"
    shell:
        """
        mkdir -p {output.index};
        hisat2_extract_splice_sites.py {input.gtf} > ref/splice_sites.txt;
        hisat2_extract_exons.py {input.gtf} > ref/exons.txt;
        hisat2-build -p 16 \
        --ss ref/splice_sites.txt \
        --exon ref/exons.txt \
        {input.fasta} {output.index}/hisat2_index > {log} 2>&1
        """


rule hisat2_align:
    input:
        index=directory("ref/hisat2_index/"),
        r1 = "results/fastp_trim/{sample}.trimmed.read1.fastq.gz",
        r2 = "results/fastp_trim/{sample}.trimmed.read2.fastq.gz"
    output:
        bam = "results/hisat2_align/{sample}.bam"
    conda:
        "hisat2"
    log:
        "logs/hisat2_align/{sample}.log"
    threads: 16
    params:
        read_groups = lambda wildcards: df.loc[wildcards.sample, ["rg_id", "rg_sm", "rg_lb"]],
        platform_unit = lambda wildcards: df.loc[wildcards.sample, "platform_unit"]
    shell:
        """
        hisat2 -p {threads} \
        --rg-id {params.read_groups[rg_id]}\
        --rg SM:{params.read_groups[rg_sm]}\
        --rg LB:{params.read_groups[rg_lb]}\
        --rg PL:ILLUMINA\
        --rg PU:{params.platform_unit} \
        --dta \
        --rna-strandness RF \
        -x {input.index}/hisat2_index\
        -1 {input.r1} \
        -2 {input.r2} \
        -S {output.bam} \
        > {log} 2>&1;

        samtools sort -@ {threads} -o {output.bam} {output.bam};
        """

# rule index_star:
#     input:
#         genome = config["genome_fasta"],
#         gtf = config["gtf"]
#     output:
#         index = directory(config["genome_index"])
#     conda:
#         "star"
#     log:
#         "star_index.log"
#     threads: 16
#     shell:
#         """
#         STAR \
#         --runThreadN {threads} \
#         --runMode genomeGenerate \
#         --genomeDir {output.index}\
#         --genomeFastaFiles {input.genome} \
#         --sjdbGTFfile {input.gtf} \
#         --sjdbOverhang 100 \
#         > {log} 2>&1
#         """

# rule align_star:
#     input:
#         r1 = "fastp_trim/{sample}_trimmed_R1.fastq.gz",
#         r2 = "fastp_trim/{sample}_trimmed_R2.fastq.gz"
#     output:
#         bam = "align_star/{sample}.bam"
#     conda:
#         "star"
#     params:
#         genome = config["genome_index"]
#     threads: 16
#     shell:
#         """
#         STAR \
#         --runThreadN {threads} \
#         --genomeDir {params.genome} \
#         --readFilesIn {input.r1} {input.r2} \
#         --readFilesCommand zcat \
#         --outFileNamePrefix align_star/{wildcards.sample} \
#         --outSAMtype BAM SortedByCoordinate \
#         > {log} 2>&1
#         """

# rule featurecounts_subread:
#     input:
#         bam = "align_star/{sample}.bam"
#     output:
#         counts = "featurecounts/{sample}.counts"
#     conda:
#         "subread"
#     params:
#         gtf = config["gtf"]
#     threads: 4   
#     shell:
#         """
#         featureCounts \
#         -T {threads} \
#         -a {params.gtf} \
#         -o {output.counts} \
#         {input.bam} \
#         > {log} 2>&1
#         """

rule multiqc:
    input:
        expand("results/fastp_trim/{sample}.json", sample=SAMPLES)
        #expand("align_star/{sample}Log.final.out", sample=config["samples"]),
        #expand("featurecounts/{sample}.counts", sample=config["samples"])
    output:
        "results/multiqc_report.html"
    conda:
        "multiqc"
    params:
        config = f"{workflow.basedir}/config/multiqc.yaml"
    shell:
        """
        multiqc -f results -o results;
        """